#!/bin/bash
set -euo pipefail

# --------------------------
# Start timer
# --------------------------
start_time=$(date +%s)

# --------------------------
# Configuration
# --------------------------
DB_FILE="thin-db.sql"
WORKDIR="/var/www/html"  # DDEV web container's project root

echo "‚ÑπÔ∏è  Note: This script will overwrite ${WORKDIR}/backups/${DB_FILE}.gz if it already exists."

# Resolve settings.ddev.php in common Drupal layouts
SETTINGS_CANDIDATES=(
  "${WORKDIR}/docroot/sites/default/settings.ddev.php"
  "${WORKDIR}/web/sites/default/settings.ddev.php"
  "${WORKDIR}/sites/default/settings.ddev.php"
)
SETTINGS_FILE=""
for f in "${SETTINGS_CANDIDATES[@]}"; do
  if [ -f "$f" ]; then SETTINGS_FILE="$f"; break; fi
done
if [ -z "${SETTINGS_FILE}" ]; then
  echo "‚ùå Error: settings.ddev.php not found in common locations."
  exit 5
fi

# Get original database name (robust across Drush versions)
ORIGINAL_DB="$(
  drush status --field=db-name --format=string 2>/dev/null || \
  drush status --fields=db-name --format=string 2>/dev/null || \
  drush sql:connect --database=default 2>/dev/null | sed -n 's/.*--database=\([^ ]*\).*/\1/p'
)"
if [ -z "${ORIGINAL_DB}" ]; then
  echo "‚ùå Error: Could not determine original database name via Drush."
  exit 6
fi

DRUSH_ARGS=""
DB_NAME=""

# Patterns to empty on the copied DB (only applied to tables that exist)
TRUNCATE_PATTERNS=(
  "^taxonomy"            # taxonomy terms and indexes
  "^comment"             # comments
  "^path_alias"          # path aliases
  "^content_moderation"  # moderation states
  "^crop"                # image crops
  "^cache"               # cache tables incl. cachetags
  "^redirect"            # redirects
  "^file_"               # file_managed, file_usage, etc.
  "^search"              # search tables, search_api_*
  "^admin_audit_trail"   # contrib
  "^simple_sitemap"      # contrib
  "^batch$"              # batch API
  "^queue$"              # queue
  "^watchdog$"           # dblog
  "^sessions$"           # sessions
  "^flood$"              # flood control
  "^history$"            # content read markers
)

# Patterns for selective cleanup (keep 1 of each type)
SELECTIVE_CLEANUP_PATTERNS=(
  "^node"                # nodes and revisions/fields
  "^media"               # media entities
)

# --------------------------
# Create copy database
# --------------------------
TARGET_DB="${ORIGINAL_DB}_thin"
echo "Creating working copy of database ${TARGET_DB}..."

DB_COPY_CONFIG=$(cat <<EOF

// Automatically added by thin-db-export script - START
\$databases['${TARGET_DB}']['default'] = [
  'database' => '${TARGET_DB}',
  'username' => 'db',
  'password' => 'db',
  'host' => 'db',
  'port' => '3306',
  'driver' => 'mysql',
];
// Automatically added by thin-db-export script - END
EOF
)

cp "$SETTINGS_FILE" "${SETTINGS_FILE}.bak"
echo "$DB_COPY_CONFIG" >> "$SETTINGS_FILE"
echo "‚úÖ Added ${TARGET_DB} configuration to settings.ddev.php"

# Create DB and grant (DDEV defaults)
TEMP_SQL="/tmp/create_db.sql"
echo "DROP DATABASE IF EXISTS \`${TARGET_DB}\`; CREATE DATABASE \`${TARGET_DB}\`;" > "$TEMP_SQL"
mysql -uroot -proot < "$TEMP_SQL"
rm -f "$TEMP_SQL"
mysql -uroot -proot -e "GRANT ALL PRIVILEGES ON \`${TARGET_DB}\`.* TO 'db'@'%';"

# Dump structure from original and import into target
echo "Copying database structure..."
STRUCTURE_FILE="/tmp/db_structure.sql"
drush sql:dump --extra="--skip-comments --skip-dump-date --no-data" --result-file="$STRUCTURE_FILE"
# Import structure using drush sql:cli to avoid version-specific flags
drush sql:cli --database="${TARGET_DB}" < "$STRUCTURE_FILE"
rm -f "$STRUCTURE_FILE"

# Copy data using mysqldump/mysql for better performance
echo "Copying data for all base tables..."
DUMP_FILE="/tmp/full_data.sql"
echo "Creating full data dump..."
drush sql:dump --extra="--skip-comments --skip-dump-date --single-transaction --no-create-info" --result-file="$DUMP_FILE"
echo "Importing data to target database..."
drush sql:cli --database="${TARGET_DB}" < "$DUMP_FILE"
rm -f "$DUMP_FILE"

DRUSH_ARGS="--database=${TARGET_DB}"
DB_NAME="${TARGET_DB}"
echo "‚úÖ Database copy created."

# --------------------------
# Thin the copied DB
# --------------------------
echo "üóëÔ∏è  Removing content and rebuildable data from ${DB_NAME} (keeping 1 node of each content type and 1 media of each type)..."

# Build and execute truncate statements in batches for better performance
echo "Building truncate statements..."
TRUNCATE_SQL="/tmp/truncate_batch.sql"
echo "SET FOREIGN_KEY_CHECKS=0;" > "$TRUNCATE_SQL"

# Collect all tables to truncate in one query
ALL_PATTERNS=$(printf "%s|" "${TRUNCATE_PATTERNS[@]}")
ALL_PATTERNS=${ALL_PATTERNS%|}  # Remove trailing |

TABLES_TO_TRUNCATE=$(drush sql:query $DRUSH_ARGS "
  SELECT TABLE_NAME
  FROM information_schema.TABLES
  WHERE TABLE_SCHEMA='${DB_NAME}' AND TABLE_NAME REGEXP '${ALL_PATTERNS}'
")

echo "Generating truncate statements for matched tables..."
for table in $TABLES_TO_TRUNCATE; do
  [ -z "$table" ] && continue
  echo "TRUNCATE TABLE \`${table}\`;" >> "$TRUNCATE_SQL"
done

echo "SET FOREIGN_KEY_CHECKS=1;" >> "$TRUNCATE_SQL"
echo "Executing batch truncate..."
drush sql:cli $DRUSH_ARGS < "$TRUNCATE_SQL" || true
rm -f "$TRUNCATE_SQL"

# Selective cleanup: keep 1 of each content type/bundle
for pattern in "${SELECTIVE_CLEANUP_PATTERNS[@]}"; do
  echo "Selective cleanup for tables matching: ${pattern}"

  if [[ "$pattern" == "^node" ]]; then
    echo "Keeping 1 node of each content type..."

    # Create batch SQL file for node cleanup
    NODE_CLEANUP_SQL="/tmp/node_cleanup.sql"
    echo "SET FOREIGN_KEY_CHECKS=0;" > "$NODE_CLEANUP_SQL"

    # Get nodes to keep (one per type) in a single query
    NODES_TO_KEEP=$(drush sql:query $DRUSH_ARGS "
      SELECT nfd1.type, MIN(nfd1.nid) as keep_nid
      FROM node_field_data nfd1
      GROUP BY nfd1.type;
    " 2>/dev/null | grep -v '^type' || true)

    if [ -n "$NODES_TO_KEEP" ]; then
      # Build list of NIDs to keep for IN clause
      KEEP_NIDS=""
      while IFS=$'\t' read -r content_type keep_nid; do
        [ -z "$content_type" ] || [ -z "$keep_nid" ] && continue
        echo "Keeping node ID ${keep_nid} for type ${content_type}"
        if [ -z "$KEEP_NIDS" ]; then
          KEEP_NIDS="$keep_nid"
        else
          KEEP_NIDS="$KEEP_NIDS,$keep_nid"
        fi
      done <<< "$NODES_TO_KEEP"

      if [ -n "$KEEP_NIDS" ]; then
        # Delete nodes not in keep list - batch operation
        echo "DELETE FROM node WHERE nid NOT IN ($KEEP_NIDS);" >> "$NODE_CLEANUP_SQL"
        echo "DELETE FROM node_field_data WHERE nid NOT IN ($KEEP_NIDS);" >> "$NODE_CLEANUP_SQL"
        echo "DELETE FROM node_field_revision WHERE nid NOT IN ($KEEP_NIDS);" >> "$NODE_CLEANUP_SQL"

        # Get all node field tables once
        NODE_FIELD_TABLES=$(drush sql:query $DRUSH_ARGS "
          SELECT TABLE_NAME FROM information_schema.TABLES
          WHERE TABLE_SCHEMA='${DB_NAME}' AND TABLE_NAME LIKE 'node\_\_field\_%';
        " 2>/dev/null || true)

        # Add field table cleanup to batch
        for table in $NODE_FIELD_TABLES; do
          [ -z "$table" ] && continue
          echo "DELETE FROM \`${table}\` WHERE entity_id NOT IN ($KEEP_NIDS);" >> "$NODE_CLEANUP_SQL"
        done

        # Get all node revision field tables once
        NODE_REVISION_TABLES=$(drush sql:query $DRUSH_ARGS "
          SELECT TABLE_NAME FROM information_schema.TABLES
          WHERE TABLE_SCHEMA='${DB_NAME}' AND TABLE_NAME LIKE 'node\_revision\_\_field\_%';
        " 2>/dev/null || true)

        # Add revision field table cleanup to batch
        for table in $NODE_REVISION_TABLES; do
          [ -z "$table" ] && continue
          echo "DELETE FROM \`${table}\` WHERE entity_id NOT IN ($KEEP_NIDS);" >> "$NODE_CLEANUP_SQL"
        done
      fi
    fi

    echo "SET FOREIGN_KEY_CHECKS=1;" >> "$NODE_CLEANUP_SQL"
    echo "Executing batch node cleanup..."
    drush sql:cli $DRUSH_ARGS < "$NODE_CLEANUP_SQL" || true
    rm -f "$NODE_CLEANUP_SQL"

  elif [[ "$pattern" == "^media" ]]; then
    echo "Keeping 1 media of each media type..."

    # Create batch SQL file for media cleanup
    MEDIA_CLEANUP_SQL="/tmp/media_cleanup.sql"
    echo "SET FOREIGN_KEY_CHECKS=0;" > "$MEDIA_CLEANUP_SQL"

    # Get media to keep (one per type) in a single query
    MEDIA_TO_KEEP=$(drush sql:query $DRUSH_ARGS "
      SELECT mfd1.bundle, MIN(mfd1.mid) as keep_mid
      FROM media_field_data mfd1
      GROUP BY mfd1.bundle;
    " 2>/dev/null | grep -v '^bundle' || true)

    if [ -n "$MEDIA_TO_KEEP" ]; then
      # Build list of MIDs to keep for IN clause
      KEEP_MIDS=""
      while IFS=$'\t' read -r media_type keep_mid; do
        [ -z "$media_type" ] || [ -z "$keep_mid" ] && continue
        echo "Keeping media ID ${keep_mid} for type ${media_type}"
        if [ -z "$KEEP_MIDS" ]; then
          KEEP_MIDS="$keep_mid"
        else
          KEEP_MIDS="$KEEP_MIDS,$keep_mid"
        fi
      done <<< "$MEDIA_TO_KEEP"

      if [ -n "$KEEP_MIDS" ]; then
        # Delete media not in keep list - batch operation
        echo "DELETE FROM media WHERE mid NOT IN ($KEEP_MIDS);" >> "$MEDIA_CLEANUP_SQL"
        echo "DELETE FROM media_field_data WHERE mid NOT IN ($KEEP_MIDS);" >> "$MEDIA_CLEANUP_SQL"
        echo "DELETE FROM media_field_revision WHERE mid NOT IN ($KEEP_MIDS);" >> "$MEDIA_CLEANUP_SQL"

        # Get all media field tables once
        MEDIA_FIELD_TABLES=$(drush sql:query $DRUSH_ARGS "
          SELECT TABLE_NAME FROM information_schema.TABLES
          WHERE TABLE_SCHEMA='${DB_NAME}' AND TABLE_NAME LIKE 'media\_\_field\_%';
        " 2>/dev/null || true)

        # Add field table cleanup to batch
        for table in $MEDIA_FIELD_TABLES; do
          [ -z "$table" ] && continue
          echo "DELETE FROM \`${table}\` WHERE entity_id NOT IN ($KEEP_MIDS);" >> "$MEDIA_CLEANUP_SQL"
        done

        # Get all media revision field tables once
        MEDIA_REVISION_TABLES=$(drush sql:query $DRUSH_ARGS "
          SELECT TABLE_NAME FROM information_schema.TABLES
          WHERE TABLE_SCHEMA='${DB_NAME}' AND TABLE_NAME LIKE 'media\_revision\_\_field\_%';
        " 2>/dev/null || true)

        # Add revision field table cleanup to batch
        for table in $MEDIA_REVISION_TABLES; do
          [ -z "$table" ] && continue
          echo "DELETE FROM \`${table}\` WHERE entity_id NOT IN ($KEEP_MIDS);" >> "$MEDIA_CLEANUP_SQL"
        done
      fi
    fi

    echo "SET FOREIGN_KEY_CHECKS=1;" >> "$MEDIA_CLEANUP_SQL"
    echo "Executing batch media cleanup..."
    drush sql:cli $DRUSH_ARGS < "$MEDIA_CLEANUP_SQL" || true
    rm -f "$MEDIA_CLEANUP_SQL"
  fi
done

# Remove pathauto state keys if table exists (safe on all sites with key_value)
drush sql:query $DRUSH_ARGS "
  DELETE FROM key_value
  WHERE collection IN ('pathauto_state.media','pathauto_state.node','pathauto_state.taxonomy_term','pathauto_state.user');
" || true

# --------------------------
# Sanitize users (generic)
# --------------------------
echo "üë§ Sanitizing users (keep uid=1)..."



# Batch user sanitization for better performance
USER_CLEANUP_SQL="/tmp/user_cleanup.sql"
echo "SET FOREIGN_KEY_CHECKS=0;" > "$USER_CLEANUP_SQL"

# Core user tables
echo "DELETE FROM users_field_data WHERE uid != 1;" >> "$USER_CLEANUP_SQL"
echo "DELETE FROM users WHERE uid != 1;" >> "$USER_CLEANUP_SQL"

# Get all user field tables and add to batch
USER_FIELD_TABLES=$(drush sql:query $DRUSH_ARGS "
  SELECT TABLE_NAME FROM information_schema.TABLES
  WHERE TABLE_SCHEMA='${DB_NAME}' AND TABLE_NAME LIKE 'user\_\_%';
" 2>/dev/null || true)

for t in $USER_FIELD_TABLES; do
  [ -z "$t" ] && continue
  echo "DELETE FROM \`${t}\` WHERE entity_id != 1;" >> "$USER_CLEANUP_SQL"
done

# Clear sessions
echo "TRUNCATE TABLE sessions;" >> "$USER_CLEANUP_SQL"

echo "SET FOREIGN_KEY_CHECKS=1;" >> "$USER_CLEANUP_SQL"
echo "Executing batch user cleanup..."
drush sql:cli $DRUSH_ARGS < "$USER_CLEANUP_SQL" || true
rm -f "$USER_CLEANUP_SQL"



# --------------------------
# Export the thinned DB
# --------------------------
echo "üì¶ Exporting database..."
drush sql:dump $DRUSH_ARGS \
  --ordered-dump \
  --extra="--skip-comments --skip-dump-date --single-transaction --no-tablespaces" \
  --result-file="${WORKDIR}/${DB_FILE}"

# --------------------------
# Compress and move
# --------------------------
echo "üóúÔ∏è  Compressing..."
cd "${WORKDIR}"
gzip -f -9 "${DB_FILE}"
mkdir -p "${WORKDIR}/backups/"
mv "${DB_FILE}.gz" "${WORKDIR}/backups/"

echo "‚úÖ Done! Final file: ${WORKDIR}/backups/${DB_FILE}.gz"
echo "File size: $(du -h ${WORKDIR}/backups/${DB_FILE}.gz | cut -f1)"

# --------------------------
# Cleanup
# --------------------------
echo "Cleaning up settings and temporary DB..."
sed -i '/\/\/ Automatically added by thin-db-export script - START/,/\/\/ Automatically added by thin-db-export script - END/d' "$SETTINGS_FILE" || true
rm -f "${SETTINGS_FILE}.bak" || true

drush sql:query "DROP DATABASE \`${TARGET_DB}\`" || true

# --------------------------
# End timer
# --------------------------
end_time=$(date +%s)
duration=$((end_time - start_time))
echo "Completed in ${duration} seconds"